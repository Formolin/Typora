# 导入项目commerce_basic

- 运行MockDataGenerate
- 生成两个文件夹
  - metastore_db
    - hive的源数据库
  - spark-warehouse
    - 数据仓库中有三张表
- 

## 附：项目规划

- 离线/实时日志采集框架

![硅谷大数据项目之电商分析平台_docx](/Users/liujiang/Documents/Typora/imgs/006tNc79ly1g5m66kehpfj30u00z5q9l.jpg)

- 后期ngrock，埋点，测试收集
- spark
- 存储
- 页面展示
  - 数据采集-》数据清洗-》数据存储-》数据呈现
  - 采集-》分析-》数仓-》Echart

# Commons

commerce.properties

```properties
#
# Copyright (c) 2018. Atguigu Inc. All Rights Reserved.
#

# jbdc配置
jdbc.datasource.size=10
jdbc.url=jdbc:mysql://localhost:3306/spark?useUnicode=true&characterEncoding=utf8
jdbc.user=root
jdbc.password=password


# 可以使用的属性如下：
#      startDate： 格式： yyyy-MM-DD   [必选]
#      endDate:    格式： yyyy-MM-DD   [必选]
#      startAge:   范围： 0 - 59
#      endAge:     范围： 0 - 59
#      professionals： 范围：professionals[0 - 59]
#      cities:     0 - 9  ((0,"北京","华北"),(1,"上海","华东"),(2,"南京","华东"),(3,"广州","华南"),(4,"三亚","华南"),(5,"武汉","华中"),(6,"长沙","华中"),(7,"西安","西北"),(8,"成都","西南"),(9,"哈尔滨","东北"))
#      sex:        范围： 0 - 1
#      keywords:   范围： ("火锅", "蛋糕", "重庆辣子鸡", "重庆小面", "呷哺呷哺", "新辣道鱼火锅", "国贸大厦", "太古商场", "日本料理", "温泉")
#      categoryIds：0 - 99，以逗号分隔
#      targetPageFlow： 0 - 99， 以逗号分隔
task.params.json={startDate:"2018-08-01", \
  endDate:"2018-08-30", \
  startAge: 20, \
  endAge: 50, \
  professionals: "",  \
  cities: "", \
  sex:"", \
  keywords:"", \
  categoryIds:"", \
  targetPageFlow:"1,2,3,4,5,6,7"}

# Kafka配置
kafka.broker.list=hadoop102:9092,hadoop103:9092,hadoop104:9092
kafka.topics=AdRealTimeLog1
```

# 新建模块session

### pom

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <parent>
        <artifactId>commerce</artifactId>
        <groupId>com.atguigu</groupId>
        <version>1.0-SNAPSHOT</version>
    </parent>
    <modelVersion>4.0.0</modelVersion>

    <artifactId>session</artifactId>
    <dependencies>

        <dependency>
            <groupId>com.atguigu</groupId>
            <artifactId>commons</artifactId>
            <version>1.0-SNAPSHOT</version>
        </dependency>

        <!-- Spark的依赖引入 -->
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_2.11</artifactId>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-sql_2.11</artifactId>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-hive_2.11</artifactId>
        </dependency>
        <!-- 引入Scala -->
        <dependency>
            <groupId>org.scala-lang</groupId>
            <artifactId>scala-library</artifactId>
        </dependency>


    </dependencies>

    <build>
        <plugins>
            <plugin>
                <!-- scala-maven-plugin插件用于在任意的maven项目中对scala代码进行编译/测试/运行/文档化 -->
                <groupId>net.alchim31.maven</groupId>
                <artifactId>scala-maven-plugin</artifactId>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-assembly-plugin</artifactId>
                <configuration>
                    <archive>
                        <manifest>
                            <mainClass>com.atguigu.session.UserVisitSessionAnalyze</mainClass>
                        </manifest>
                    </archive>
                    <descriptorRefs>
                        <descriptorRef>jar-with-dependencies</descriptorRef>
                    </descriptorRefs>
                </configuration>
            </plugin>
        </plugins>
    </build>


</project>
```

### 创建文件

```scala

```

![千锋大数据教程：1、checkpoint-1_mp4](/Users/liujiang/Documents/Typora/imgs/006tNc79ly1g5qyek6uvzj313m0h4k54.jpg)

- conf 包

  - ConfigurationManager类

  ```scala
  /**
  * 配置工具类
  */
  object ConfigurationManager {
  
  // 创建用于初始化配置生成器实例的参数对象
  private val params = new Parameters()
  // FileBasedConfigurationBuilder:产生一个传入的类的实例对象
  // FileBasedConfiguration:融合 FileBased 与 Configuration 的接口
  // PropertiesConfiguration:从一个或者多个文件读取配置的标准配置加载器
  // configure():通过 params 实例初始化配置生成器
  // 向 FileBasedConfigurationBuilder()中传入一个标准配置加载器类，生成一个加载器类的实例对象，然后通过 params 参数对其初始化
  private val builder = new FileBasedConfigurationBuilder[FileBasedConfiguration](classOf [PropertiesConfiguration])
  .configure(params.properties().setFileName("commerce.properties"))
  
  // 通过 getConfiguration 获取配置对象
  val config = builder.getConfiguration()
  
  }
  ```

- constant 包

  ```scala
  /**
  * 常量接口
  */
  object Constants {
  
  /**
  * 项目配置相关的常量
  */
  val JDBC_DATASOURCE_SIZE = "jdbc.datasource.size" val JDBC_URL = "jdbc.url"
  val JDBC_USER = "jdbc.user"
  val JDBC_PASSWORD = "jdbc.password"
      val KAFKA_TOPICS = "kafka.topics"
  
  /**
  * Spark 作业相关的常量
  */
  val SPARK_APP_NAME_SESSION = "UserVisitSessionAnalyzeSpark" val SPARK_APP_NAME_PAGE = "PageOneStepConvertRateSpark"
  val FIELD_SESSION_ID = "sessionid"
  val FIELD_SEARCH_KEYWORDS = "searchKeywords"
  val FIELD_CLICK_CATEGORY_IDS = "clickCategoryIds" val FIELD_AGE = "age"
  val FIELD_PROFESSIONAL = "professional" val FIELD_CITY = "city"
  val FIELD_SEX = "sex"
  val FIELD_VISIT_LENGTH = "visitLength" val FIELD_STEP_LENGTH = "stepLength" val FIELD_START_TIME = "startTime"
  val FIELD_CLICK_COUNT = "clickCount" val FIELD_ORDER_COUNT = "orderCount" val FIELD_PAY_COUNT = "payCount"
  val FIELD_CATEGORY_ID = "categoryid" val SESSION_COUNT = "session_count"
  val TIME_PERIOD_1s_3s = "1s_3s" val TIME_PERIOD_4s_6s = "4s_6s" val TIME_PERIOD_7s_9s = "7s_9s"
  val TIME_PERIOD_10s_30s = "10s_30s" val TIME_PERIOD_30s_60s = "30s_60s" val TIME_PERIOD_1m_3m = "1m_3m"
  val TIME_PERIOD_3m_10m = "3m_10m" val TIME_PERIOD_10m_30m = "10m_30m" val TIME_PERIOD_30m = "30m"
  
  val STEP_PERIOD_1_3 = "1_3" val STEP_PERIOD_4_6 = "4_6" val STEP_PERIOD_7_9 = "7_9"
  val STEP_PERIOD_10_30 = "10_30" val STEP_PERIOD_30_60 = "30_60" val STEP_PERIOD_60 = "60"
  
  /**
  * 任务相关的常量
  */
  val TASK_PARAMS = "task.params.json" val PARAM_START_DATE = "startDate" val PARAM_END_DATE = "endDate"
  val PARAM_START_AGE = "startAge" val PARAM_END_AGE = "endAge"
  val PARAM_PROFESSIONALS = "professionals" val PARAM_CITIES = "cities"
  val PARAM_SEX = "sex"
  val PARAM_KEYWORDS = "keywords"
  val PARAM_CATEGORY_IDS = "categoryIds"
  val PARAM_TARGET_PAGE_FLOW = "targetPageFlow"
  }
  ```

  

- model 包DateModel

  ```scala
  /**
  *用户访问动作表
  *
  *@param date	用户点击行为的日期
  *@param user_id	用户的 ID
  *@param session_id	Session 的 ID
  *@param page_id	某个页面的 ID
  *@param action_time	点击行为的时间点
  *@param search_keyword	用户搜索的关键词
  *@param click_category_id	某一个商品品类的 ID
  *@param click_product_id	某一个商品的 ID
  *@param order_category_ids	一次订单中所有品类的 ID 集合
  *@param order_product_ids	一次订单中所有商品的 ID 集合
  *@param pay_category_ids	一次支付中所有品类的 ID 集合
  *@param pay_product_ids	一次支付中所有商品的 ID 集合
  *@param city_id	城市 ID
  */
  case class UserVisitAction(date: String,
  user_id: Long, session_id: String, page_id: Long, action_time: String, search_keyword: String, click_category_id: Long, click_product_id: Long,
  order_category_ids: String, order_product_ids: String, pay_category_ids: String, pay_product_ids: String, city_id: Long
  )
  
  /**
  *用户信息表
  *
  *@param user_id	用户的 ID
  *@param username	用户的名称
  *@param name	用户的名字
  *@param age	用户的年龄
  *@param professional 用户的职业
  *@param city	用户所在的城市
  *@param sex	用户的性别
  */
  case class UserInfo(user_id: Long,
  username: String, name: String, age: Int,
  professional: String, city: String,
  sex: String
  )
  
  /**
  *产品表
  *
  *@param product_id	商品的 ID
  
  *@param product_name 商品的名称
  *@param extend_info 商品额外的信息
  */
  case class ProductInfo(product_id: Long,
  product_name: String, extend_info: String
  )
  ```

  

-  utils 包

  | 类名称class     | **解析**                                                     |
  | --------------- | ------------------------------------------------------------ |
  | **DateUtils**   | 时间工具类负责时间的格式化、判断时间先后、计算时间差值、获取指定日期等工作 |
  | **NumberUtils** | 数字工具类负责数字的格式化工作                               |
  | **ParamUtils**  | 参数工具类负责从 JSON 对象中提取参数                         |
  | **StringUtils** | 字符串工具类负责字符串是否为空判断、字符串截断与补全、从拼接字符串中提取字段、给拼接字符串中字段设置值等工作 |
  | **ValidUtils**  | 校验工具类负责校验数据中的指定字段是否在指定范围范围内、校验数据中的指定字段中是否有值与参数字段相同、校验数据中的指定字段是否与参数字段相同等工作 |

- mock

  | **Object**                   | **解析**                                                     |
  | ---------------------------- | ------------------------------------------------------------ |
  | **MockDataGenerate**         | 离线模拟数据生成负责生成离线模拟数据并写入 Hive 表中，模拟数据包括用户行为信息、用户信息、产品数据信息等 |
  | **MockRealtimeDataGenerate** | 实时模拟数据生成负责生成实时模拟数据并写入 Kafka 中，实时模拟数据为实时广告数据 |

  - 运行MockDataGenerate生成数据（hive表，sparksql可以直接查询）

# 需求一：**Session** **各范围访问步长、访问时长占比统计**

```scala
/**
  * 用户访问动作表
  *
  * @param date               用户点击行为的日期
  * @param user_id            用户的 ID
  * @param session_id         Session 的 ID
  * @param page_id            某个页面的 ID
  * @param action_time        点击行为的时间点
  * @param search_keyword     用户搜索的关键词
  * @param click_category_id  某一个商品品类的 ID
  * @param click_product_id   某一个商品的 ID
  * @param order_category_ids 一次订单中所有品类的 ID 集合
  * @param order_product_ids  一次订单中所有商品的 ID 集合
  * @param pay_category_ids   一次支付中所有品类的 ID 集合
  * @param pay_product_ids    一次支付中所有商品的 ID 集合
  * @param city_id            城市 ID
  */
case class UserVisitAction(date: String,
                           user_id: Long, 
                           session_id: String,
                           page_id: Long,
                           action_time: String, 
                           search_keyword: String,
                           click_category_id: Long, 
                           click_product_id: Long,
                           order_category_ids: String,
                           order_product_ids: String, 
                           pay_category_ids: String,
                           pay_product_ids: String, 
                           city_id: Long
                          )
```

```sh
SessionID | 搜索关键字 | 点击品类 | 访问时长 | 访问步长|开始时间
Session_Id | Search_Keywords | Click_Category_Id | Visit_Length | Step_Length | Start_Time|Age|Professional|Sex|City
```

**MySQL** 存储结构解析

```sql
-- ----------------------------
--  Table structure for `session_aggr_stat`
-- ----------------------------
DROP TABLE IF EXISTS `session_aggr_stat`; CREATE TABLE `session_aggr_stat` (
`taskid` varchar(255) DEFAULT NULL,
`session_count` int(11) DEFAULT NULL,
`visit_length_1s_3s_ratio` double DEFAULT NULL,
`visit_length_4s_6s_ratio` double DEFAULT NULL,
`visit_length_7s_9s_ratio` double DEFAULT NULL,
`visit_length_10s_30s_ratio` double DEFAULT NULL,
`visit_length_30s_60s_ratio` double DEFAULT NULL,
`visit_length_1m_3m_ratio` double DEFAULT NULL,
`visit_length_3m_10m_ratio` double DEFAULT NULL,
`visit_length_10m_30m_ratio` double DEFAULT NULL,
`visit_length_30m_ratio` double DEFAULT NULL,
`step_length_1_3_ratio` double DEFAULT NULL,
`step_length_4_6_ratio` double DEFAULT NULL,
`step_length_7_9_ratio` double DEFAULT NULL,
`step_length_10_30_ratio` double DEFAULT NULL,
`step_length_30_60_ratio` double DEFAULT NULL,
`step_length_60_ratio` double DEFAULT NULL, KEY `idx_task_id` (`taskid`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
```

```scala
case class UserInfo(user_id: Long,           //用户ID
                    username: String,	                  //用户名
                    name: String,	                 // 用户真实姓名
                    age: Int,	                 // 年龄
                    professional: String,              // 职业
                    city: String,	                 // 城市
                    sex: String	                  //性别
                   )

```

```scala
import org.apache.spark.SparkConf
import org.apache.spark.sql.SparkSession

object Demo1 {
  def main(args: Array[String]): Unit = {
    val sparkConf = new SparkConf().setAppName("Stock").setMaster("local[2]")
    val spark = SparkSession.builder().config(sparkConf).getOrCreate()
    import spark.implicits._
    val tbStockRdd = spark.sparkContext.textFile("/Users/liujiang/Documents/hadoop-test-txt/tbStock.txt")
    val tbStockDS = tbStockRdd.map(_.split(",")).map(attr => tbStock(attr(0), attr(1), attr(2))).toDS
    tbStockDS.createTempView("tbStock")
    val rdd = spark.sql("select * from tbStock").as[tbStock].rdd
    rdd.foreach(println(_))
    /*
    tbStock(HMJSL00005564,DOGNGUAN,2006-1-7)
    tbStock(HMJSL00005565,GUIHE,2006-1-7)
    tbStock(HMJSL00005566,ZM,2006-1-7)
     */
  }
}

```

```scala
object Demo {
  def main(args: Array[String]): Unit = {
    var time = "2017-10-31 20:27:53"
    val currentTime = DateUtils.parseTime(time)
    println(currentTime)//Tue Oct 31 20:27:53 CST 2017
    var start = DateUtils.parseTime("2017-10-12 20:27:53")
    var end = DateUtils.parseTime("2017-11-12 20:27:53")
    val bool = start.after(currentTime)//start 在 当前时间 之后吗？ false
    val bool1 = start.before(currentTime)//start 在 当前时间 之前吗？ true
    println(bool1)
  }
}
```

```scala
/*
 * Copyright (c) 2018. Atguigu Inc. All Rights Reserved.
 */

//***************** 输出表 *********************

/**
  * 聚合统计表
  *
  * @param taskid                       当前计算批次的ID
  * @param session_count                所有Session的总和
  * @param visit_length_1s_3s_ratio     1-3sSession访问时长占比
  * @param visit_length_4s_6s_ratio     4-6sSession访问时长占比
  * @param visit_length_7s_9s_ratio     7-9sSession访问时长占比
  * @param visit_length_10s_30s_ratio   10-30sSession访问时长占比
  * @param visit_length_30s_60s_ratio   30-60sSession访问时长占比
  * @param visit_length_1m_3m_ratio     1-3mSession访问时长占比
  * @param visit_length_3m_10m_ratio    3-10mSession访问时长占比
  * @param visit_length_10m_30m_ratio   10-30mSession访问时长占比
  * @param visit_length_30m_ratio       30mSession访问时长占比
  * @param step_length_1_3_ratio        1-3步长占比
  * @param step_length_4_6_ratio        4-6步长占比
  * @param step_length_7_9_ratio        7-9步长占比
  * @param step_length_10_30_ratio      10-30步长占比
  * @param step_length_30_60_ratio      30-60步长占比
  * @param step_length_60_ratio         大于60步长占比
  */
case class SessionAggrStat(taskid: String,
                           session_count: Long,
                           visit_length_1s_3s_ratio: Double,
                           visit_length_4s_6s_ratio: Double,
                           visit_length_7s_9s_ratio: Double,
                           visit_length_10s_30s_ratio: Double,
                           visit_length_30s_60s_ratio: Double,
                           visit_length_1m_3m_ratio: Double,
                           visit_length_3m_10m_ratio: Double,
                           visit_length_10m_30m_ratio: Double,
                           visit_length_30m_ratio: Double,
                           step_length_1_3_ratio: Double,
                           step_length_4_6_ratio: Double,
                           step_length_7_9_ratio: Double,
                           step_length_10_30_ratio: Double,
                           step_length_30_60_ratio: Double,
                           step_length_60_ratio: Double
                          )

/**
  * Session随机抽取表
  *
  * @param taskid             当前计算批次的ID
  * @param sessionid          抽取的Session的ID
  * @param startTime          Session的开始时间
  * @param searchKeywords     Session的查询字段
  * @param clickCategoryIds   Session点击的类别id集合
  */
case class SessionRandomExtract(taskid:String,
                                sessionid:String,
                                startTime:String,
                                searchKeywords:String,
                                clickCategoryIds:String)

/**
  * Session随机抽取详细表
  *
  * @param taskid            当前计算批次的ID
  * @param userid            用户的ID
  * @param sessionid         Session的ID
  * @param pageid            某个页面的ID
  * @param actionTime        点击行为的时间点
  * @param searchKeyword     用户搜索的关键词
  * @param clickCategoryId   某一个商品品类的ID
  * @param clickProductId    某一个商品的ID
  * @param orderCategoryIds  一次订单中所有品类的ID集合
  * @param orderProductIds   一次订单中所有商品的ID集合
  * @param payCategoryIds    一次支付中所有品类的ID集合
  * @param payProductIds     一次支付中所有商品的ID集合
  **/
case class SessionDetail(taskid:String,
                         userid:Long,
                         sessionid:String,
                         pageid:Long,
                         actionTime:String,
                         searchKeyword:String,
                         clickCategoryId:Long,
                         clickProductId:Long,
                         orderCategoryIds:String,
                         orderProductIds:String,
                         payCategoryIds:String,
                         payProductIds:String)

/**
  * 品类Top10表
  * @param taskid
  * @param categoryid
  * @param clickCount
  * @param orderCount
  * @param payCount
  */
case class Top10Category(taskid:String,
                         categoryid:Long,
                         clickCount:Long,
                         orderCount:Long,
                         payCount:Long)

/**
  * Top10 Session
  * @param taskid
  * @param categoryid
  * @param sessionid
  * @param clickCount
  */
case class Top10Session(taskid:String,
                        categoryid:Long,
                        sessionid:String,
                        clickCount:Long)

```

```scala
import org.apache.spark.util.AccumulatorV2

import scala.collection.mutable

class SessionStatAccumulator extends AccumulatorV2[String,mutable.HashMap[String,Int]]{
  val countMap = new mutable.HashMap[String,Int]()
  override def isZero: Boolean = countMap.isEmpty

  override def copy(): AccumulatorV2[String,mutable.HashMap[String,Int]] = {
    val acc = new SessionStatAccumulator

    acc.countMap++=this.countMap  //往map集合里追加map集合
    acc
  }

  override def reset(): Unit = {
    countMap.clear()
  }

  override def add(v: String): Unit = {
    if(!countMap.contains(v)){
      countMap+=(v->0)
    }

    countMap.update(v,countMap(v)+1)
  }

  override def merge(other:AccumulatorV2[String,mutable.HashMap[String,Int]]): Unit = {
    other match {
      case  acc:SessionStatAccumulator=>
        acc.countMap.foldLeft(this.countMap){
          case (map,(k,v))=>map+=(k->(map.getOrElse(k,0)+v))
        }
    }
  }

  override def value: mutable.HashMap[String,Int] = {
    this.countMap
  }
}

```



```scala
import java.util.{Date, UUID}

import commons.conf.ConfigurationManager
import commons.constant.Constants
import commons.model.{UserInfo, UserVisitAction}
import commons.utils._
import net.sf.json.JSONObject
import org.apache.spark.SparkConf
import org.apache.spark.rdd.RDD
import org.apache.spark.sql.{SaveMode, SparkSession}

import scala.collection.mutable

object SessionStaticAgg {


  def main(args: Array[String]): Unit = {
    //读取配置,拿到task.params.json
    val jsonStr = ConfigurationManager.config.getString(Constants.TASK_PARAMS)
    println("jsonStr=" + jsonStr)
    //转成json对象
    val taskParam = JSONObject.fromObject(jsonStr)
    println("taskParam=" + taskParam)
    //taskParam={"startDate":"2019-08-01","endDate":"2029-08-30","startAge":20,"endAge":50,"professionals":"","cities":"","sex":"","keywords":"","categoryIds":"","targetPageFlow":"1,2,3,4,5,6,7"}
    //作为数据主键，区别不同的spark任务生成的统计数据
    val taskUUID = UUID.randomUUID().toString

    val sparkConf = new SparkConf().setAppName("session").setMaster("local[*]")

    val sparkSession = SparkSession.builder().config(sparkConf).enableHiveSupport().getOrCreate()

    val actionRDD = getAction(sparkSession, taskParam)

    //    actionRDD.foreach(println(_))
    //    UserVisitAction(2019-09-25,45,bd7fab540a844583ba4837ec16612c75,9,2019-09-25 0:08:05,null,13,60,null,null,null,null,0)
    //    UserVisitAction(2019-09-25,45,bd7fab540a844583ba4837ec16612c75,0,2019-09-25 0:20:01,null,82,47,null,null,null,null,6)
    //    转换  k,v结构
    val sessionId2ActionRDD = actionRDD.map(
      item => (item.session_id, item)
    )
    //rdd[(sid,iterable(UserVisitAction)]
    /*
    (1b1cc932f65943feab468d0700c3c3c6,UserVisitAction(2019-09-25,4,1b1cc932f65943feab468d0700c3c3c6,2,2019-09-25 13:12:55,null,-1,-1,null,null,86,42,4))
    (1b1cc932f65943feab468d0700c3c3c6,UserVisitAction(2019-09-25,4,1b1cc932f65943feab468d0700c3c3c6,1,2019-09-25 13:58:39,null,2,75,null,null,null,null,6))
     */
    //    sessionId2ActionRDD.foreach(println(_))
    val sessionId2GroupRDD = sessionId2ActionRDD.groupByKey()

    //标记当前RDD的校验点。它会被保存为在由SparkContext.setCheckpointDir()方法设置的checkpoint目录下的文件集中的一个文件。
    // 简而言之就是当前RDD的校验点被保存为了一个文件，而这个文件在一个目录下，这个目录下有不少的这样的文件，
    // 这个目录是由SparkContext.setCheckpointDir()方法设置的。并且所有从父RDD中引用的文件都将被删除。
    // 这个函数必须在所有的job前被调用，运行在这个RDD上。它被强烈的建议保存在内存中，否则，也就是从内存转出存入文件，则需要重新计算它。
    //    sparkSession.sparkContext.setCheckpointDir()

    //进行缓存
    sessionId2GroupRDD.cache()
    //sessionId2GroupRDD.checkpoint()
    //    sessionId2GroupRDD.foreach(println(_))
    /*
    (7fe9dd146e3b4d63ab66e15da1c9d60a,CompactBuffer(UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,2,2019-09-25 21:42:31,null,24,7,null,null,null,null,3), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,2,2019-09-25 21:23:43,洗面奶,-1,-1,null,null,null,null,9), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,7,2019-09-25 21:52:43,null,-1,-1,null,null,95,97,6), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,7,2019-09-25 21:27:13,null,11,11,null,null,null,null,9), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,9,2019-09-25 21:27:04,null,-1,-1,null,null,81,11,8), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,7,2019-09-25 21:00:28,null,-1,-1,null,null,75,60,9), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,5,2019-09-25 21:57:24,null,23,76,null,null,null,null,3), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,0,2019-09-25 21:16:39,null,-1,-1,null,null,82,50,4), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,5,2019-09-25 21:18:25,卫生纸,-1,-1,null,null,null,null,2), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,1,2019-09-25 21:39:08,null,-1,-1,null,null,20,34,3), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,1,2019-09-25 21:27:11,华为手机,-1,-1,null,null,null,null,6), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,9,2019-09-25 21:56:04,null,-1,-1,null,null,50,55,7), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,3,2019-09-25 21:04:28,null,-1,-1,null,null,58,78,2), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,0,2019-09-25 21:41:13,null,-1,-1,26,54,null,null,8), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,7,2019-09-25 21:54:12,null,-1,-1,null,null,12,79,7), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,9,2019-09-25 21:49:38,null,-1,-1,null,null,36,1,0), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,2,2019-09-25 21:11:19,null,-1,-1,20,22,null,null,4), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,6,2019-09-25 21:08:15,保温杯,-1,-1,null,null,null,null,7), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,5,2019-09-25 21:39:37,null,46,63,null,null,null,null,2), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,9,2019-09-25 21:40:46,null,-1,-1,null,null,4,43,3), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,3,2019-09-25 21:53:56,null,-1,-1,66,85,null,null,7), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,3,2019-09-25 21:04:21,null,-1,-1,45,31,null,null,3), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,8,2019-09-25 21:26:43,null,-1,-1,69,93,null,null,9), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,1,2019-09-25 21:41:46,机器学习,-1,-1,null,null,null,null,0), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,2,2019-09-25 21:24:22,null,-1,-1,null,null,13,88,2), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,1,2019-09-25 21:48:41,小龙虾,-1,-1,null,null,null,null,7), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,8,2019-09-25 21:30:38,null,96,77,null,null,null,null,4), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,1,2019-09-25 21:04:08,保温杯,-1,-1,null,null,null,null,8), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,1,2019-09-25 21:28:49,小龙虾,-1,-1,null,null,null,null,8), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,4,2019-09-25 21:21:31,null,-1,-1,null,null,23,18,6), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,6,2019-09-25 21:56:32,null,11,20,null,null,null,null,4), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,5,2019-09-25 21:12:50,null,-1,-1,6,92,null,null,4), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,5,2019-09-25 21:41:29,null,30,44,null,null,null,null,3), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,3,2019-09-25 21:16:38,null,-1,-1,null,null,0,60,5), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,7,2019-09-25 21:18:48,null,-1,-1,null,null,45,90,9), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,5,2019-09-25 21:26:29,null,-1,-1,null,null,25,94,6), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,3,2019-09-25 21:27:54,null,78,59,null,null,null,null,8), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,3,2019-09-25 21:45:43,null,-1,-1,27,74,null,null,6), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,6,2019-09-25 21:20:51,null,9,98,null,null,null,null,0), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,6,2019-09-25 21:14:38,null,-1,-1,50,55,null,null,8), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,9,2019-09-25 21:45:41,null,-1,-1,null,null,90,52,3), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,3,2019-09-25 21:32:39,null,86,70,null,null,null,null,1), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,2,2019-09-25 21:18:06,null,-1,-1,29,70,null,null,4), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,2,2019-09-25 21:51:21,null,-1,-1,null,null,68,41,8), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,7,2019-09-25 21:38:35,null,40,74,null,null,null,null,7), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,9,2019-09-25 21:21:04,null,-1,-1,null,null,87,9,7), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,6,2019-09-25 21:19:19,null,-1,-1,null,null,42,32,8), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,2,2019-09-25 21:38:07,null,0,24,null,null,null,null,7), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,3,2019-09-25 21:11:24,卫生纸,-1,-1,null,null,null,null,7), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,9,2019-09-25 21:56:28,null,-1,-1,27,91,null,null,7), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,6,2019-09-25 21:42:55,小龙虾,-1,-1,null,null,null,null,6), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,3,2019-09-25 21:52:26,null,-1,-1,null,null,95,70,2), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,4,2019-09-25 21:00:12,null,-1,-1,56,92,null,null,7), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,0,2019-09-25 21:36:57,null,-1,-1,35,51,null,null,3), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,9,2019-09-25 21:42:50,吸尘器,-1,-1,null,null,null,null,7), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,8,2019-09-25 21:06:11,联想笔记本,-1,-1,null,null,null,null,5), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,7,2019-09-25 21:49:57,null,-1,-1,41,87,null,null,6), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,4,2019-09-25 21:25:25,null,-1,-1,62,29,null,null,6), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,2,2019-09-25 21:16:47,null,-1,-1,null,null,76,4,3), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,5,2019-09-25 21:54:06,null,-1,-1,83,17,null,null,8), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,6,2019-09-25 21:14:02,吸尘器,-1,-1,null,null,null,null,7), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,7,2019-09-25 21:56:56,null,-1,-1,41,79,null,null,2), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,5,2019-09-25 21:58:38,卫生纸,-1,-1,null,null,null,null,3), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,5,2019-09-25 21:38:24,null,68,27,null,null,null,null,5), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,9,2019-09-25 21:44:36,null,95,4,null,null,null,null,2), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,6,2019-09-25 21:41:44,null,45,97,null,null,null,null,0), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,0,2019-09-25 21:02:58,null,-1,-1,null,null,86,45,4), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,4,2019-09-25 21:37:51,吸尘器,-1,-1,null,null,null,null,2), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,9,2019-09-25 21:12:25,null,24,44,null,null,null,null,6), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,6,2019-09-25 21:46:25,null,-1,-1,null,null,84,54,4), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,6,2019-09-25 21:57:26,null,-1,-1,26,73,null,null,9), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,7,2019-09-25 21:38:11,null,-1,-1,52,63,null,null,0), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,8,2019-09-25 21:54:58,null,0,16,null,null,null,null,5), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,1,2019-09-25 21:21:35,null,54,29,null,null,null,null,5), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,9,2019-09-25 21:50:02,null,-1,-1,null,null,19,7,8), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,1,2019-09-25 21:10:20,联想笔记本,-1,-1,null,null,null,null,8), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,1,2019-09-25 21:21:24,洗面奶,-1,-1,null,null,null,null,9), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,4,2019-09-25 21:43:54,null,3,29,null,null,null,null,4), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,9,2019-09-25 21:38:02,吸尘器,-1,-1,null,null,null,null,6), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,6,2019-09-25 21:03:10,null,5,52,null,null,null,null,6), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,2,2019-09-25 21:00:14,null,-1,-1,null,null,96,77,9), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,4,2019-09-25 21:47:15,null,67,43,null,null,null,null,5), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,2,2019-09-25 21:14:10,null,-1,-1,68,73,null,null,0), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,8,2019-09-25 21:48:57,null,-1,-1,null,null,42,97,3), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,4,2019-09-25 21:14:00,华为手机,-1,-1,null,null,null,null,9), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,7,2019-09-25 21:18:19,null,-1,-1,null,null,56,86,7), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,8,2019-09-25 21:54:13,null,-1,-1,null,null,18,93,1), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,0,2019-09-25 21:21:51,null,-1,-1,null,null,67,98,9), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,2,2019-09-25 21:18:32,null,-1,-1,86,99,null,null,3), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,4,2019-09-25 21:28:31,null,-1,-1,null,null,50,97,3), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,6,2019-09-25 21:01:17,null,-1,-1,22,50,null,null,7), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,6,2019-09-25 21:24:29,null,-1,-1,79,21,null,null,5), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,5,2019-09-25 21:17:06,null,-1,-1,null,null,19,49,3), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,8,2019-09-25 21:34:06,null,-1,-1,null,null,76,88,2), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,7,2019-09-25 21:03:28,null,-1,-1,93,68,null,null,6), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,0,2019-09-25 21:44:56,机器学习,-1,-1,null,null,null,null,8), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,7,2019-09-25 21:19:55,null,63,58,null,null,null,null,6), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,5,2019-09-25 21:25:08,华为手机,-1,-1,null,null,null,null,4), UserVisitAction(2019-09-25,98,7fe9dd146e3b4d63ab66e15da1c9d60a,2,2019-09-25 21:47:47,null,-1,-1,86,21,null,null,8)))
    (252cc1ee46174dc2a09464df424aa66e,CompactBuffer(UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,9,2019-09-25 4:52:54,null,69,30,null,null,null,null,9), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,4,2019-09-25 4:10:52,联想笔记本,-1,-1,null,null,null,null,4), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,2,2019-09-25 4:13:32,小龙虾,-1,-1,null,null,null,null,5), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,6,2019-09-25 4:52:41,null,26,16,null,null,null,null,3), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,5,2019-09-25 4:35:05,联想笔记本,-1,-1,null,null,null,null,5), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,2,2019-09-25 4:12:54,null,-1,-1,48,51,null,null,0), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,8,2019-09-25 4:39:22,洗面奶,-1,-1,null,null,null,null,7), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,6,2019-09-25 4:51:22,null,-1,-1,73,29,null,null,9), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,2,2019-09-25 4:14:19,null,0,58,null,null,null,null,6), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,1,2019-09-25 4:20:00,null,77,50,null,null,null,null,3), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,0,2019-09-25 4:36:40,洗面奶,-1,-1,null,null,null,null,5), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,8,2019-09-25 4:54:25,小龙虾,-1,-1,null,null,null,null,6), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,4,2019-09-25 4:46:45,null,38,34,null,null,null,null,4), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,0,2019-09-25 4:36:28,联想笔记本,-1,-1,null,null,null,null,5), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,2,2019-09-25 4:44:40,null,44,30,null,null,null,null,4), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,0,2019-09-25 4:29:01,null,76,10,null,null,null,null,8), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,1,2019-09-25 4:52:12,null,-1,-1,29,52,null,null,7), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,5,2019-09-25 4:32:36,null,-1,-1,99,40,null,null,9), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,5,2019-09-25 4:01:41,null,-1,-1,null,null,27,26,0), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,5,2019-09-25 4:13:19,null,66,55,null,null,null,null,3), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,0,2019-09-25 4:54:14,null,-1,-1,71,94,null,null,3), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,6,2019-09-25 4:07:51,null,-1,-1,null,null,71,49,6), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,3,2019-09-25 4:29:16,null,-1,-1,12,60,null,null,7), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,5,2019-09-25 4:56:23,null,-1,-1,null,null,34,63,7), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,9,2019-09-25 4:54:55,null,67,57,null,null,null,null,6), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,9,2019-09-25 4:30:34,Lamer,-1,-1,null,null,null,null,1), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,9,2019-09-25 4:39:02,null,-1,-1,87,81,null,null,4), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,6,2019-09-25 4:16:50,null,-1,-1,7,15,null,null,4), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,3,2019-09-25 4:31:10,null,29,13,null,null,null,null,8), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,3,2019-09-25 4:47:45,null,-1,-1,null,null,29,1,7), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,5,2019-09-25 4:40:24,null,37,29,null,null,null,null,5), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,3,2019-09-25 4:48:27,null,-1,-1,73,87,null,null,7), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,9,2019-09-25 4:08:49,小龙虾,-1,-1,null,null,null,null,3), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,7,2019-09-25 4:48:56,null,-1,-1,38,80,null,null,6), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,0,2019-09-25 4:06:02,null,-1,-1,null,null,36,29,9), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,4,2019-09-25 4:51:10,联想笔记本,-1,-1,null,null,null,null,5), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,9,2019-09-25 4:23:58,null,-1,-1,null,null,82,57,2), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,0,2019-09-25 4:29:44,null,-1,-1,null,null,27,4,7), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,5,2019-09-25 4:52:03,null,62,25,null,null,null,null,1), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,1,2019-09-25 4:49:56,null,-1,-1,null,null,73,88,3), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,4,2019-09-25 4:42:36,null,45,87,null,null,null,null,9), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,8,2019-09-25 4:09:55,null,-1,-1,null,null,29,2,8), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,3,2019-09-25 4:14:02,机器学习,-1,-1,null,null,null,null,0), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,1,2019-09-25 4:39:02,null,76,6,null,null,null,null,2), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,9,2019-09-25 4:26:29,机器学习,-1,-1,null,null,null,null,4), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,0,2019-09-25 4:31:17,Lamer,-1,-1,null,null,null,null,7), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,3,2019-09-25 4:39:12,null,-1,-1,null,null,88,94,2), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,2,2019-09-25 4:44:28,null,-1,-1,null,null,90,97,4), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,5,2019-09-25 4:14:41,联想笔记本,-1,-1,null,null,null,null,0), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,6,2019-09-25 4:25:16,Lamer,-1,-1,null,null,null,null,0), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,0,2019-09-25 4:33:01,null,-1,-1,null,null,33,22,0), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,7,2019-09-25 4:47:18,null,-1,-1,null,null,14,6,6), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,2,2019-09-25 4:40:01,机器学习,-1,-1,null,null,null,null,9), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,7,2019-09-25 4:00:53,null,70,38,null,null,null,null,5), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,1,2019-09-25 4:13:48,小龙虾,-1,-1,null,null,null,null,4), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,4,2019-09-25 4:36:12,小龙虾,-1,-1,null,null,null,null,9), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,1,2019-09-25 4:58:33,null,-1,-1,71,60,null,null,5), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,9,2019-09-25 4:05:04,null,-1,-1,55,78,null,null,5), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,6,2019-09-25 4:19:11,null,-1,-1,null,null,60,47,3), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,2,2019-09-25 4:37:08,null,-1,-1,93,26,null,null,0), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,0,2019-09-25 4:08:58,小龙虾,-1,-1,null,null,null,null,1), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,0,2019-09-25 4:06:38,null,-1,-1,34,37,null,null,5), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,6,2019-09-25 4:55:23,null,-1,-1,null,null,16,44,4), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,3,2019-09-25 4:33:13,null,-1,-1,null,null,65,10,0), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,8,2019-09-25 4:28:57,null,-1,-1,null,null,87,82,2), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,5,2019-09-25 4:56:35,null,-1,-1,null,null,7,26,5), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,1,2019-09-25 4:07:26,小龙虾,-1,-1,null,null,null,null,0), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,1,2019-09-25 4:00:36,卫生纸,-1,-1,null,null,null,null,8), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,4,2019-09-25 4:32:25,null,32,1,null,null,null,null,4), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,4,2019-09-25 4:04:20,null,-1,-1,null,null,51,31,3), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,7,2019-09-25 4:57:40,机器学习,-1,-1,null,null,null,null,9), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,2,2019-09-25 4:46:35,卫生纸,-1,-1,null,null,null,null,4), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,9,2019-09-25 4:35:07,null,60,70,null,null,null,null,2), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,2,2019-09-25 4:02:39,null,-1,-1,null,null,35,79,8), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,0,2019-09-25 4:07:41,null,64,63,null,null,null,null,9), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,4,2019-09-25 4:48:14,Lamer,-1,-1,null,null,null,null,3), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,4,2019-09-25 4:47:47,null,-1,-1,5,37,null,null,6), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,3,2019-09-25 4:07:23,null,-1,-1,null,null,91,56,9), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,1,2019-09-25 4:03:48,吸尘器,-1,-1,null,null,null,null,3), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,3,2019-09-25 4:25:41,null,-1,-1,95,56,null,null,1), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,2,2019-09-25 4:45:40,null,-1,-1,null,null,63,21,1), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,9,2019-09-25 4:51:44,保温杯,-1,-1,null,null,null,null,6), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,9,2019-09-25 4:00:49,null,-1,-1,28,41,null,null,9), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,0,2019-09-25 4:14:34,null,-1,-1,24,60,null,null,9), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,2,2019-09-25 4:37:35,null,-1,-1,null,null,40,79,9), UserVisitAction(2019-09-25,30,252cc1ee46174dc2a09464df424aa66e,8,2019-09-25 4:51:25,华为手机,-1,-1,null,null,null,null,4)))
    (734a4f364f7f4a17bcf5be1d1df42267,CompactBuffer(UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,5,2019-09-25 16:15:44,null,-1,-1,94,98,null,null,6), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,9,2019-09-25 16:32:04,null,-1,-1,65,13,null,null,9), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,0,2019-09-25 16:04:26,null,-1,-1,null,null,31,73,2), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,1,2019-09-25 16:42:04,null,-1,-1,null,null,12,92,1), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,2,2019-09-25 16:19:05,null,-1,-1,null,null,64,93,9), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,4,2019-09-25 16:12:35,Lamer,-1,-1,null,null,null,null,8), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,5,2019-09-25 16:42:02,洗面奶,-1,-1,null,null,null,null,3), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,3,2019-09-25 16:41:28,null,-1,-1,42,56,null,null,5), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,7,2019-09-25 16:15:57,null,-1,-1,null,null,34,10,0), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,0,2019-09-25 16:11:46,null,70,94,null,null,null,null,4), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,2,2019-09-25 16:43:04,null,-1,-1,null,null,94,1,0), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,3,2019-09-25 16:43:30,null,-1,-1,null,null,5,80,7), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,5,2019-09-25 16:30:26,null,54,65,null,null,null,null,2), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,8,2019-09-25 16:46:15,null,-1,-1,88,35,null,null,6), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,8,2019-09-25 16:09:12,null,-1,-1,17,71,null,null,0), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,3,2019-09-25 16:22:51,null,82,12,null,null,null,null,9), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,3,2019-09-25 16:45:40,Lamer,-1,-1,null,null,null,null,3), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,0,2019-09-25 16:00:30,卫生纸,-1,-1,null,null,null,null,8), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,9,2019-09-25 16:29:06,null,-1,-1,null,null,16,50,6), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,9,2019-09-25 16:31:53,null,-1,-1,null,null,63,33,1), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,0,2019-09-25 16:41:11,null,14,12,null,null,null,null,9), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,6,2019-09-25 16:48:09,null,-1,-1,null,null,13,71,7), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,3,2019-09-25 16:44:05,null,-1,-1,null,null,67,68,7), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,4,2019-09-25 16:42:58,null,-1,-1,null,null,80,45,2), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,4,2019-09-25 16:43:49,卫生纸,-1,-1,null,null,null,null,6), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,3,2019-09-25 16:54:51,联想笔记本,-1,-1,null,null,null,null,6), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,4,2019-09-25 16:55:14,null,63,74,null,null,null,null,7), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,0,2019-09-25 16:45:14,null,-1,-1,null,null,98,19,9), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,7,2019-09-25 16:38:04,null,-1,-1,null,null,23,83,6), UserVisitAction(2019-09-25,52,734a4f364f7f4a17bcf5be1d1df42267,9,2019-09-25 16:58:36,null,-1,-1,91,95,null,null,5)))
     */
    val sessionId2FullInfoRDD = getFullInfoData(sparkSession, sessionId2GroupRDD)
    //    userIdAggrInfoRDD.foreach(println(_))
    /*
    (31,sessionid=be3fcdf3c7c844039ff707a4f37dee98|searchKeywords=保温杯,机器学习,卫生纸,联想笔记本,华为手机|categoryid=97,71,72|visitLength=2758|stepLength=16|startTime=2019-09-25)
    (31,sessionid=c9c3e1bded414da8a8257113bf4f025d|searchKeywords=|categoryid=62|visitLength=0|stepLength=1|startTime=2019-09-25)
    (30,sessionid=52293bb8abfd4c03b86c426452367d73|searchKeywords=Lamer,保温杯,机器学习,洗面奶,卫生纸|categoryid=16,23,35,11,98,81,78|visitLength=3446|stepLength=25|startTime=2019-09-25)
    (3,sessionid=6b995148b4c746909d039ff66a3a9f94|searchKeywords=联想笔记本|categoryid=38,8,3,55,87|visitLength=3010|stepLength=15|startTime=2019-09-25)
     */
    //    userIdAggrInfoRDD.foreach(println(_))
    //    (84c64964c13640d4b4cffd5ff511c95e,sessionid=84c64964c13640d4b4cffd5ff511c95e|searchKeywords=洗面奶,Lamer,苹果,机器学习|categoryid=59,87,39,58,52,38,11|visitLength=3172|stepLength=21|startTime=2019-09-25|age=27|professional=professional0|sex=female|city=city91)

    //自定义累加器
    val sessionStatAccumulator = new SessionStatAccumulator
    sparkSession.sparkContext.register(sessionStatAccumulator)

    //过滤用户数据
    val sessionId2FilterRDD = getFilterDate(taskParam, sessionId2FullInfoRDD, sessionStatAccumulator)
        sessionId2FilterRDD.foreach(println(_))

    //需求一：各范围session占比统计
    getSessionRatio(sparkSession, taskUUID, sessionStatAccumulator.value)

  }

  def getSessionRatio(sparkSession: SparkSession, taskUUID: String, value: mutable.HashMap[String, Int]) = {
    val session_count = value.getOrElse(Constants.SESSION_COUNT, 1).toDouble
    val stepLength_1_3 = value.getOrElse(Constants.STEP_PERIOD_1_3, 0)
    val stepLength_4_6 = value.getOrElse(Constants.STEP_PERIOD_4_6, 0)
    val stepLength_7_9 = value.getOrElse(Constants.STEP_PERIOD_7_9, 0)
    val stepLength_10_30 = value.getOrElse(Constants.STEP_PERIOD_10_30, 0)
    val stepLength_30_60 = value.getOrElse(Constants.STEP_PERIOD_30_60, 0)
    val stepLength_60 = value.getOrElse(Constants.STEP_PERIOD_60, 0)

    val visitLength_1s_3s = value.getOrElse(Constants.TIME_PERIOD_1s_3s, 0)
    val visitLength_4s_6s = value.getOrElse(Constants.TIME_PERIOD_4s_6s, 0)
    val visitLength_7s_9s = value.getOrElse(Constants.TIME_PERIOD_7s_9s, 0)
    val visitLength_10s_30s = value.getOrElse(Constants.TIME_PERIOD_10s_30s, 0)
    val visitLength_30s_60s = value.getOrElse(Constants.TIME_PERIOD_30s_60s, 0)
    val visitLength_1m_3m = value.getOrElse(Constants.TIME_PERIOD_1m_3m, 0)
    val visitLength_3m_10m = value.getOrElse(Constants.TIME_PERIOD_3m_10m, 0)
    val visitLength_10m_30m = value.getOrElse(Constants.TIME_PERIOD_10m_30m, 0)
    val visitLength_30m = value.getOrElse(Constants.TIME_PERIOD_30m, 0)

    val visit_length_1s_3s_ratio = NumberUtils.formatDouble(visitLength_1s_3s / session_count, 2)
    val visitLength_4s_6s_ratio = NumberUtils.formatDouble(visitLength_4s_6s / session_count, 2)
    val visitLength_7s_9s_ratio = NumberUtils.formatDouble(visitLength_7s_9s / session_count, 2)
    val visitLength_10s_30s_ratio = NumberUtils.formatDouble(visitLength_10s_30s / session_count, 2)
    val visitLength_30s_60s_ratio = NumberUtils.formatDouble(visitLength_30s_60s / session_count, 2)
    val visitLength_1m_3m_ratio = NumberUtils.formatDouble(visitLength_1m_3m / session_count, 2)
    val visitLength_3m_10m_ratio = NumberUtils.formatDouble(visitLength_3m_10m / session_count, 2)
    val visitLength_10m_30m_ratio = NumberUtils.formatDouble(visitLength_10m_30m / session_count, 2)
    val visitLength_30m_ratio = NumberUtils.formatDouble(visitLength_30m / session_count, 2)

    val stepLength_1_3_ratio = NumberUtils.formatDouble(stepLength_1_3 / session_count, 2)
    val stepLength_4_6_ratio = NumberUtils.formatDouble(stepLength_4_6 / session_count, 2)
    val stepLength_7_9_ratio = NumberUtils.formatDouble(stepLength_7_9 / session_count, 2)
    val stepLength_10_30_ratio = NumberUtils.formatDouble(stepLength_10_30 / session_count, 2)
    val stepLength_30_60_ratio = NumberUtils.formatDouble(stepLength_30_60 / session_count, 2)
    val stepLength_60_ratio = NumberUtils.formatDouble(stepLength_60 / session_count, 2)

    val aggrStat = SessionAggrStat(taskUUID, session_count.toInt, visit_length_1s_3s_ratio, visitLength_4s_6s_ratio, visitLength_7s_9s_ratio, visitLength_10s_30s_ratio, visitLength_30s_60s_ratio, visitLength_1m_3m_ratio, visitLength_3m_10m_ratio, visitLength_10m_30m_ratio, visitLength_30m_ratio, stepLength_1_3_ratio, stepLength_4_6_ratio, stepLength_7_9_ratio, stepLength_10_30_ratio, stepLength_30_60_ratio, stepLength_60_ratio)
    //写入mysql
    val aggrStatRDD = sparkSession.sparkContext.makeRDD(Array(aggrStat))
    import sparkSession.implicits._
    aggrStatRDD.toDF().write
      .format("jdbc")
      .option("url",ConfigurationManager.config.getString(Constants.JDBC_URL))
      .option("user",ConfigurationManager.config.getString(Constants.JDBC_USER))
      .option("password",ConfigurationManager.config.getString(Constants.JDBC_PASSWORD))
      .option("dbtable","session_stat_0926")
      .mode(SaveMode.Append)
      .save()
  }

  def getFilterDate(taskParam: JSONObject, sessionId2FullInfoRDD: RDD[(String, String)], sessionStatAccumulator: SessionStatAccumulator) = {
    val startAge = ParamUtils.getParam(taskParam, Constants.PARAM_START_AGE)
    val endAge = ParamUtils.getParam(taskParam, Constants.PARAM_END_AGE)
    val professional = ParamUtils.getParam(taskParam, Constants.PARAM_PROFESSIONALS)
    val cities = ParamUtils.getParam(taskParam, Constants.PARAM_CITIES)
    val sex = ParamUtils.getParam(taskParam, Constants.PARAM_SEX)
    val keywords = ParamUtils.getParam(taskParam, Constants.PARAM_KEYWORDS)
    val categoryIds = ParamUtils.getParam(taskParam, Constants.PARAM_CATEGORY_IDS)


    var filterInfo = (if (startAge != null) Constants.PARAM_START_AGE + "=" + startAge + "|" else "") +
      (if (endAge != null) Constants.PARAM_END_AGE + "=" + endAge + "|" else "") +
      (if (professional != null) Constants.PARAM_PROFESSIONALS + "=" + professional + "|" else "") +
      (if (cities != null) Constants.PARAM_CITIES + "=" + cities + "|" else "") +
      (if (sex != null) Constants.PARAM_SEX + "=" + sex + "|" else "") +
      (if (keywords != null) Constants.PARAM_KEYWORDS + "=" + keywords + "|" else "") +
      (if (categoryIds != null) Constants.PARAM_CATEGORY_IDS + "=" + categoryIds + "|" else "")

    if (filterInfo.endsWith("\\|")) {
      filterInfo = filterInfo.substring(0, filterInfo.length - 1)
    }
    val sessionId2FilterRDD = sessionId2FullInfoRDD.filter {
      case (sid, fullInfo) =>
        var success = true

        if (!ValidUtils.between(fullInfo, Constants.FIELD_AGE, filterInfo, Constants.PARAM_START_AGE, Constants.PARAM_END_AGE)) {
          success = false
        } else if (!ValidUtils.in(fullInfo, Constants.FIELD_PROFESSIONAL, filterInfo, Constants.PARAM_PROFESSIONALS)) {
          success = false
        } else if (!ValidUtils.in(fullInfo, Constants.FIELD_CITY, filterInfo, Constants.PARAM_CITIES)) {
          success = false
        } else if (!ValidUtils.equal(fullInfo, Constants.FIELD_SEX, filterInfo, Constants.PARAM_SEX)) {
          success = false
        } else if (!ValidUtils.in(fullInfo, Constants.FIELD_SEARCH_KEYWORDS, filterInfo, Constants.PARAM_KEYWORDS)) {
          success = false
        } else if (!ValidUtils.in(fullInfo, Constants.FIELD_CATEGORY_ID, filterInfo, Constants.PARAM_CATEGORY_IDS)) {
          success = false
        }

        if (success) {
          sessionStatAccumulator.add(Constants.SESSION_COUNT)

          def calculateVisitLength(visitLength: Long) = {
            if (visitLength > 1 && visitLength <= 3) {
              sessionStatAccumulator.add(Constants.TIME_PERIOD_1s_3s)
            } else if (visitLength > 4 && visitLength <= 6) {
              sessionStatAccumulator.add(Constants.TIME_PERIOD_4s_6s)
            } else if (visitLength > 7 && visitLength <= 9) {
              sessionStatAccumulator.add(Constants.TIME_PERIOD_7s_9s)
            } else if (visitLength > 10 && visitLength <= 30) {
              sessionStatAccumulator.add(Constants.TIME_PERIOD_10s_30s)
            } else if (visitLength > 30 && visitLength <= 60) {
              sessionStatAccumulator.add(Constants.TIME_PERIOD_30s_60s)
            } else if (visitLength > 60 && visitLength <= 180) {
              sessionStatAccumulator.add(Constants.TIME_PERIOD_1m_3m)
            } else if (visitLength > 180 && visitLength <= 600) {
              sessionStatAccumulator.add(Constants.TIME_PERIOD_3m_10m)
            } else if (visitLength > 600 && visitLength <= 600) {
              sessionStatAccumulator.add(Constants.TIME_PERIOD_3m_10m)
            } else if (visitLength > 1800) {
              sessionStatAccumulator.add(Constants.TIME_PERIOD_30m)
            }
          }

          def calculateStepLength(stepLength: Long) = {
            if (stepLength >= 1 && stepLength <= 3) {
              sessionStatAccumulator.add(Constants.STEP_PERIOD_1_3)
            } else if (stepLength >= 4 && stepLength <= 6) {
              sessionStatAccumulator.add(Constants.STEP_PERIOD_4_6)
            } else if (stepLength >= 7 && stepLength <= 9) {
              sessionStatAccumulator.add(Constants.STEP_PERIOD_7_9)
            } else if (stepLength >= 10 && stepLength <= 30) {
              sessionStatAccumulator.add(Constants.STEP_PERIOD_10_30)
            } else if (stepLength >= 30 && stepLength <= 60) {
              sessionStatAccumulator.add(Constants.STEP_PERIOD_30_60)
            } else if (stepLength > 60) {
              sessionStatAccumulator.add(Constants.STEP_PERIOD_60)
            }
          }

          val stepLen = StringUtils.getFieldFromConcatString(fullInfo, "\\|", Constants.FIELD_STEP_LENGTH).toLong
          val visitLen = StringUtils.getFieldFromConcatString(fullInfo, "\\|", Constants.FIELD_VISIT_LENGTH).toLong

          calculateVisitLength(visitLen)
          calculateStepLength(stepLen)
        }
        success
    }

    sessionId2FilterRDD
  }

  def getFullInfoData(sparkSession: SparkSession, sessionId2GroupRDD: RDD[(String, Iterable[UserVisitAction])]) = {
    val userIdAggrInfoRDD = sessionId2GroupRDD.map {
      case (sid, iterableUserVisitAction) =>
        //        初始值
        var startTime: Date = null
        var endTime: Date = null
        var userId = -1L
        var searchKeyWord = new StringBuffer
        var clickCateId = new StringBuffer
        var stepLen = 0 //访问步长

        for (action <- iterableUserVisitAction) {
          if (userId == -1L) {
            //遍历第一条数据中的CompactBuffer里的第一条数据，只需要赋值一次就可以，因为用户id是一个人
            userId = action.user_id
          }

          var actionTime = DateUtils.parseTime(action.action_time)
          if (startTime == null || startTime.after(actionTime)) {
            startTime = actionTime
          }
          if (endTime == null || endTime.before(actionTime)) {
            endTime = actionTime
          }

          var searchKW = action.search_keyword
          var clickCI = action.click_category_id

          if (StringUtils.isNotEmpty(searchKW) && !searchKeyWord.toString.contains(searchKW))
            searchKeyWord
              .append(searchKW + ",")

          if (clickCI != -1L && !clickCateId.toString.contains(clickCI)) {
            clickCateId.append(clickCI + ",")
          }

          stepLen += 1

        }
        //循环外 等starttime 和 endtime 更新后在统计时长
        //去除最后一个逗号
        val skw = StringUtils.trimComma(searchKeyWord.toString)
        val cci = StringUtils.trimComma(clickCateId.toString)
        val vistiLen = (endTime.getTime - startTime.getTime) / 1000 //获取的是毫秒/1000 = 秒
      val aggrInfo = {
        Constants.FIELD_SESSION_ID + "=" + sid + "|" +
          Constants.FIELD_SEARCH_KEYWORDS + "=" + skw + "|" +
          Constants.FIELD_CATEGORY_ID + "=" + cci + "|" +
          Constants.FIELD_VISIT_LENGTH + "=" + vistiLen + "|" +
          Constants.FIELD_STEP_LENGTH + "=" + stepLen + "|" +
          Constants.FIELD_START_TIME + "=" + DateUtils.formatDate(startTime)
      }

        (userId, aggrInfo)
    }

    //联立user_info表
    val sql = "select * from user_info"
    import sparkSession.implicits._
    val userInfoRDD = sparkSession.sql(sql).as[UserInfo].rdd.map(item => (item.user_id, item))
    //(userid,(aggrInfo,userInfo)
    userIdAggrInfoRDD.join(userInfoRDD).map {
      case (userId, (aggrInfo, userInfo)) =>
        val age = userInfo.age
        val professional = userInfo.professional
        val sex = userInfo.sex
        val city = userInfo.city

        var fullInfo = {
          aggrInfo + "|" + Constants.FIELD_AGE + "=" + age + "|" +
            Constants.FIELD_PROFESSIONAL + "=" + professional + "|" +
            Constants.FIELD_SEX + "=" + sex + "|" +
            Constants.FIELD_CITY + "=" + city
        }
        //获取sid,按|切割字符串，在获取字段名，得到值
        val sid = StringUtils.getFieldFromConcatString(aggrInfo, "\\|", Constants.FIELD_SESSION_ID)

        (sid, fullInfo)
    }

  }

  def getAction(sparkSession: SparkSession, taskParam: JSONObject) = {
    val startDate = ParamUtils.getParam(taskParam, Constants.PARAM_START_DATE)
    val endDate = ParamUtils.getParam(taskParam, Constants.PARAM_END_DATE)
    println("startDate=" + startDate)
    println("endDate=" + endDate)
    //startDate=2019-08-01
    //endDate=2029-08-30

    val sql = "select * from user_visit_action where date>='" + startDate + "' and date<='" + endDate + "'"
    //隐式转换
    import sparkSession.implicits._
    //spark转成sql，在转成实体类，在转成rdd返回

    sparkSession.sql(sql).as[UserVisitAction].rdd
    //    sparkSession.sql(sql).as[UserVisitAction].show()
    //    sparkSession.sql(sql).show()
    //    sparkSession.sql(sql)


  }
}

```

# 需求二：session随机抽取

```scala
 //需求二：session随机抽取
    // sessionId2FilterRDD： RDD[(sid, fullInfo)] 一个session对应一条数据，也就是一个fullInfo
    sessionRandomExtract(sparkSession, taskUUID, sessionId2FilterRDD)
```

```scala
 def sessionRandomExtract(sparkSession: SparkSession, taskUUID: String, sessionId2FilterRDD: RDD[(String, String)]): Unit = {
    // dateHour2FullInfoRDD: RDD[(dateHour, fullInfo)]
    val dateHour2FullInfoRDD = sessionId2FilterRDD.map {
      case (sid, fullInfo) =>
        val startTime = StringUtils.getFieldFromConcatString(fullInfo, "\\|", Constants.FIELD_START_TIME)
        // dateHour: yyyy-MM-dd_HH
        val dateHour = DateUtils.getDateHour(startTime)
        (dateHour, fullInfo)
    }
    /*
        (
          2019-09-26_14,
          sessionid=d15ef61c1c7a4cf8a03858a5b10eeb2e|
          searchKeywords=联想笔记本,华为手机,苹果,保温杯,机器学习,吸尘器,Lamer,卫生纸|
          categoryid=2,12,79,64,15,25,73,93,46,95,48,28,71,7,99,77,16,85,92,66,64,26|
          visitLength=3512|
          stepLength=85|
          startTime=2019-09-26 14:00:20|
          age=20|
          professional=professional29|
          sex=female|
          city=city30
        )

        (
          2019-09-26_01,
          sessionid=1955d6864c3549e396c6bcee091e7a61|
          searchKeywords=联想笔记本,华为手机,吸尘器,小龙虾,保温杯,苹果,卫生纸,Lamer,洗面奶,机器学习|
          categoryid=5,68,34,84,41,43,13,55,14,63,91,63,29,64,70|
          visitLength=3485|
          stepLength=94|
          startTime=2019-09-26 01:00:01|
          age=20|
          professional=professional29|
          sex=female|
          city=city30
         )
     */

    // hourCountMap: Map[(dateHour, count)]
    // 统计每个key对应的value个数
    //  key:c2,values:3
    //  key:c1,values:2
    val hourCountMap = dateHour2FullInfoRDD.countByKey()
    /*
      (2019-09-26_20,2494)
      (2019-09-26_00,2407)
      (2019-09-26_17,2563)
      (2019-09-26_18,2485)
      (2019-09-26_22,2493)
     */
    // dateHourCountMap: Map[(date, Map[(hour, count)])]
    val dateHourCountMap = new mutable.HashMap[String, mutable.HashMap[String, Long]]()
    for ((dateHour, count) <- hourCountMap) {
      val date = dateHour.split("_")(0)
      val hour = dateHour.split("_")(1)

      dateHourCountMap.get(date) match {
        case None => dateHourCountMap(date) = new mutable.HashMap[String, Long]()
          dateHourCountMap(date) += (hour -> count)
        case Some(map) => dateHourCountMap(date) += (hour -> count)
      }
    }
    //(2019-09-26,
    // Map(12 -> 2480,
    // 15 -> 2483,
    // 09 -> 2501,
    // 00 -> 2407,
    // 21 -> 2517,
    // 03 -> 2462,
    // 18 -> 2485,
    // 06 -> 2476,
    // 17 -> 2563,
    // 05 -> 2414,
    // 11 -> 2479,
    // 08 -> 2550,
    // 14 -> 2537,
    // 20 -> 2494,
    // 02 -> 2552,
    // 22 -> 2493,
    // 01 -> 2486,
    // 16 -> 2494,
    // 04 -> 2547,
    // 10 -> 2479,
    // 19 -> 2501,
    // 13 -> 2602,
    // 07 -> 2583))
    // 解决问题一： 一共有多少天： dateHourCountMap.size
    //              一天抽取多少条：100 / dateHourCountMap.size
    val extractPerDay = 100 / dateHourCountMap.size

    // 解决问题二： 一天有多少session：dateHourCountMap(date).values.sum
    // 解决问题三： 一个小时有多少session：dateHourCountMap(date)(hour)
    val dateHourExtractIndexListMap = new mutable.HashMap[String, mutable.HashMap[String, ListBuffer[Int]]]()

    // dateHourCountMap: Map[(date, Map[(hour, count)])]
    for ((date, hourCountMap) <- dateHourCountMap) {
      //获取hourCountMap的value，取总和
      val dateSessionCount = hourCountMap.values.sum
      //匹配模式，相当于if else
      dateHourExtractIndexListMap.get(date) match {
        //如果key未获取到，就新创建一个并添加
        case None => dateHourExtractIndexListMap(date) = new mutable.HashMap[String, ListBuffer[Int]]()
          generateRandomIndexList(extractPerDay, dateSessionCount, hourCountMap, dateHourExtractIndexListMap(date))
        case Some(map) =>
          generateRandomIndexList(extractPerDay, dateSessionCount, hourCountMap, dateHourExtractIndexListMap(date))
      }
    }

    //    dateHourExtractIndexListMap.foreach(println(_))
    // 到目前为止，我们获得了每个小时要抽取的session的index
    //2019-09-26,Map(12 -> ListBuffer(1177, 1231, 156, 284), 15 -> ListBuffer(983, 1696, 1074, 1554)

    // 广播大变量，提升任务性能
    val dateHourExtractIndexListMapBd = sparkSession.sparkContext.broadcast(dateHourExtractIndexListMap)

    // dateHour2FullInfoRDD: RDD[(dateHour, fullInfo)]
    // dateHour2GroupRDD: RDD[(dateHour, iterableFullInfo)]
    val dateHour2GroupRDD = dateHour2FullInfoRDD.groupByKey()
    //    dateHour2GroupRDD.foreach(println(_))
    /*

    2019-09-26_04,

    CompactBuffer(

    sessionid=27c81317d6b14aebb113cf0b0955e96b|
    searchKeywords=卫生纸,机器学习,保温杯,吸尘器,小龙虾,联想笔记本,苹果,洗面奶,Lamer|
    categoryid=12,48,84,58,92,63,24,30,65,69,43,90,90,45,62,95,8|
    visitLength=3501|stepLength=70|startTime=2019-09-26 04:00:17|age=39|
    professional=professional24|sex=male|city=city7,

     sessionid=49b40c1deda94a6b8e44e6bd8f2c5cb8|
     searchKeywords=Lamer,保温杯,联想笔记本,华为手机,苹果,卫生纸,机器学习|
     categoryid=45,63,21,16,35,24,22,31,42,60,13,79,11,79|visitLength=3317
     |stepLength=57|startTime=2019-09-26 04:01:52|age=39|
     professional=professional24|sex=male|city=city7
     */

    // extractSessionRDD: RDD[SessionRandomExtract]
    val extractSessionRDD = dateHour2GroupRDD.flatMap {
      case (dateHour, iterableFullInfo) =>
        val date = dateHour.split("_")(0)
        val hour = dateHour.split("_")(1)
        //ListBuffer(1177, 1231, 156, 284)
        val extractList = dateHourExtractIndexListMapBd.value.get(date).get(hour)

        val extractSessionArrayBuffer = new ArrayBuffer[SessionRandomExtract]()

        var index = 0

        for (fullInfo <- iterableFullInfo) {
          if (extractList.contains(index)) {
            val sessionId = StringUtils.getFieldFromConcatString(fullInfo, "\\|", Constants.FIELD_SESSION_ID)
            val startTime = StringUtils.getFieldFromConcatString(fullInfo, "\\|", Constants.FIELD_START_TIME)
            val searchKeywords = StringUtils.getFieldFromConcatString(fullInfo, "\\|", Constants.FIELD_SEARCH_KEYWORDS)
            val clickCategories = StringUtils.getFieldFromConcatString(fullInfo, "\\|", Constants.FIELD_CLICK_CATEGORY_IDS)

            val extractSession = SessionRandomExtract(taskUUID, sessionId, startTime, searchKeywords, clickCategories)

            extractSessionArrayBuffer += extractSession
          }
          index += 1
        }

        extractSessionArrayBuffer
    }
//    extractSessionRDD.foreach(println(_))
    //SessionRandomExtract(5dba54bb-8044-4de7-8138-3a126701f70a,85e9a45f31b64d479a1c0f1eeb42250a,2019-09-26 03:00:32,Lamer,吸尘器,机器学习,联想笔记本,华为手机,洗面奶,小龙虾,苹果,null)
    //SessionRandomExtract(5dba54bb-8044-4de7-8138-3a126701f70a,0f4c1330a3a34011ad7e9ca376c393e6,2019-09-26 03:00:15,保温杯,洗面奶,联想笔记本,Lamer,华为手机,苹果,机器学习,小龙虾,吸尘器,卫生纸,null)
    //每小时抽取4个

    import sparkSession.implicits._
    extractSessionRDD.toDF().write
      .format("jdbc")
      .option("url", ConfigurationManager.config.getString(Constants.JDBC_URL))
      .option("user",ConfigurationManager.config.getString(Constants.JDBC_USER))
      .option("password", ConfigurationManager.config.getString(Constants.JDBC_PASSWORD))
      .option("dbtable", "session_extract_0926")
      .mode(SaveMode.Append)
      .save()
  }
```

```scala
 def generateRandomIndexList(extractPerDay: Long, //一天要抽取多少个
                              daySessionCount: Long, //一天一共有多少个
                              hourCountMap: mutable.HashMap[String, Long], //每个小时有多少个
                              //生成每小时抽取多少个的索引随机数
                              hourListMap: mutable.HashMap[String, ListBuffer[Int]]): Unit = {
    for ((hour, count) <- hourCountMap) {
      // 获取一个小时要抽取多少条数据
      var hourExrCount = ((count / daySessionCount.toDouble) * extractPerDay).toInt
      // 避免一个小时要抽取的数量超过这个小时的总数
      if (hourExrCount > count) {
        hourExrCount = count.toInt
      }

      val random = new Random()

      hourListMap.get(hour) match {
        case None => hourListMap(hour) = new ListBuffer[Int]
          for (i <- 0 until hourExrCount) {
            var index = random.nextInt(count.toInt)
            while (hourListMap(hour).contains(index)) {
              index = random.nextInt(count.toInt)
            }
            hourListMap(hour).append(index)
          }
        case Some(list) =>
          for (i <- 0 until hourExrCount) {
            var index = random.nextInt(count.toInt)
            while (hourListMap(hour).contains(index)) {
              index = random.nextInt(count.toInt)
            }
            hourListMap(hour).append(index)
          }
      }
    }
  }

```

# 需求三：Top10热门品类

```scala
// sessionId2ActionRDD: RDD[(sessionId, action)]
    // sessionId2FilterRDD : RDD[(sessionId, FullInfo)]  符合过滤条件的
    // sessionId2FilterActionRDD: join   只返回左右都匹配上的
    // 获取所有符合过滤条件的action数据
    val sessionId2FilterActionRDD = sessionId2ActionRDD.join(sessionId2FilterRDD).map{
      case (sessionId, (action, fullInfo)) =>
        (sessionId, action)
    }

//    sessionId2FilterActionRDD.foreach(println(_))
//    (1fe06487471e4b828268fea7eec18596,UserVisitAction(2019-09-26,17,1fe06487471e4b828268fea7eec18596,0,2019-09-26 2:08:41,null,95,76,null,null,null,null,6))
//    (1fe06487471e4b828268fea7eec18596,UserVisitAction(2019-09-26,17,1fe06487471e4b828268fea7eec18596,3,2019-09-26 2:32:19,null,22,69,null,null,null,null,8))
//    (935619e814a04d798262867e818c96a5,UserVisitAction(2019-09-26,24,935619e814a04d798262867e818c96a5,9,2019-09-26 6:33:22,null,0,58,null,null,null,null,1))
//    (935619e814a04d798262867e818c96a5,UserVisitAction(2019-09-26,24,935619e814a04d798262867e818c96a5,1,2019-09-26 6:17:15,null,-1,-1,34,54,null,null,8))
//    (935619e814a04d798262867e818c96a5,UserVisitAction(2019-09-26,24,935619e814a04d798262867e818c96a5,0,2019-09-26 6:38:20,null,-1,-1,78,70,null,null,6))

```

```scala
def getClickCount(sessionId2FilterActionRDD: RDD[(String, UserVisitAction)]) = {

    //    val clickFilterRDD = sessionId2FilterActionRDD.filter{
    //      case (sessionId, action) => action.click_category_id != -1L
    //    }
    // 先进行过滤，把点击行为对应的action保留下来
    val clickFilterRDD = sessionId2FilterActionRDD.filter(item => item._2.click_category_id != -1L)

    // 进行格式转换，为reduceByKey做准备
    val clickNumRDD = clickFilterRDD.map {
      case (sessionId, action) => (action.click_category_id, 1L)
    }

    clickNumRDD.reduceByKey(_ + _)
  }


def getOrderCount(sessionId2FilterActionRDD: RDD[(String, UserVisitAction)]) = {
    val orderFilterRDD = sessionId2FilterActionRDD.filter(item => item._2.order_category_ids != null)

    val orderNumRDD = orderFilterRDD.flatMap {
      // action.order_category_ids.split(","): Array[String]
      // action.order_category_ids.split(",").map(item => (item.toLong, 1L)
      // 先将我们的字符串拆分成字符串数组，然后使用map转化数组中的每个元素，
      // 原来我们的每一个元素都是一个string，现在转化为（long, 1L）
      case (sessionId, action) => action.order_category_ids.split(",").
        map(item => (item.toLong, 1L))
    }

    orderNumRDD.reduceByKey(_ + _)
  }


def getPayCount(sessionId2FilterActionRDD: RDD[(String, UserVisitAction)]) = {
    val payFilterRDD = sessionId2FilterActionRDD.filter(item => item._2.pay_category_ids != null)

    val payNumRDD = payFilterRDD.flatMap {
      case (sid, action) =>
        action.pay_category_ids.split(",").map(item => (item.toLong, 1L))
    }

    payNumRDD.reduceByKey(_ + _)
  }
```

```scala
 def getFullCount(cid2CidRDD: RDD[(Long, Long)],
                   cid2ClickCountRDD: RDD[(Long, Long)],
                   cid2OrderCountRDD: RDD[(Long, Long)],
                   cid2PayCountRDD: RDD[(Long, Long)]) = {
    val cid2ClickInfoRDD = cid2CidRDD.leftOuterJoin(cid2ClickCountRDD).map {
      case (cid, (categoryId, option)) =>
        val clickCount = if (option.isDefined) option.get else 0
        val aggrCount = Constants.FIELD_CATEGORY_ID + "=" + cid + "|" +
          Constants.FIELD_CLICK_COUNT + "=" + clickCount

        (cid, aggrCount)
    }

    val cid2OrderInfoRDD = cid2ClickInfoRDD.leftOuterJoin(cid2OrderCountRDD).map {
      case (cid, (clickInfo, option)) =>
        val orderCount = if (option.isDefined) option.get else 0
        val aggrInfo = clickInfo + "|" +
          Constants.FIELD_ORDER_COUNT + "=" + orderCount

        (cid, aggrInfo)
    }

    val cid2PayInfoRDD = cid2OrderInfoRDD.leftOuterJoin(cid2PayCountRDD).map {
      case (cid, (orderInfo, option)) =>
        val payCount = if (option.isDefined) option.get else 0
        val aggrInfo = orderInfo + "|" +
          Constants.FIELD_PAY_COUNT + "=" + payCount

        (cid, aggrInfo)
    }

    cid2PayInfoRDD
  }
```

### leftOuterJoin

- leftOuterJoin类似于SQL中的左外关联left outer join，返回结果以前面的RDD为主，关联不上的记录为空。只能用于两个RDD之间的关联，如果要多个RDD关联，多关联几次即可。

```scala
var rdd1 = sc.makeRDD(Array(("A","1"),("B","2"),("C","3")),2)
var rdd2 = sc.makeRDD(Array(("A","a"),("C","c"),("D","d")),2)
 
scala> rdd1.leftOuterJoin(rdd2).collect
res11: Array[(String, (String, Option[String]))] = Array((B,(2,None)), (A,(1,Some(a))), (C,(3,Some(c))))

```

- 自定义SortKey

```scala
case class SortKey(clickCount:Long, orderCount:Long, payCount:Long) extends Ordered[SortKey]{
  // this.compare(that)
  // this compare that
  // compare > 0   this > that
  // compare <0    this < that
  override def compare(that: SortKey): Int = {
    if(this.clickCount - that.clickCount != 0){
      return (this.clickCount - that.clickCount).toInt
    }else if(this.orderCount - that.orderCount != 0){
      return (this.orderCount - that.orderCount).toInt
    }else{
      return (this.payCount - that.payCount).toInt
    }
  }
}

```

```scala
def top10PopularCategories(sparkSession: SparkSession,
                             taskUUID: String,
                             sessionId2FilterActionRDD: RDD[(String, UserVisitAction)]) = {
    // 第一步：获取所有发生过点击、下单、付款的品类
    var cid2CidRDD = sessionId2FilterActionRDD.flatMap {
      case (sid, action) =>
        val categoryBuffer = new ArrayBuffer[(Long, Long)]()

        // 点击行为
        if (action.click_category_id != -1) {
          categoryBuffer += ((action.click_category_id, action.click_category_id))
        } else if (action.order_category_ids != null) {
          for (orderCid <- action.order_category_ids.split(","))
            categoryBuffer += ((orderCid.toLong, orderCid.toLong))
        } else if (action.pay_category_ids != null) {
          for (payCid <- action.pay_category_ids.split(","))
            categoryBuffer += ((payCid.toLong, payCid.toLong))
        }
        categoryBuffer
    }
    //    cid2CidRDD.foreach(println(_))
    /*
      (13,13)
      (85,85)
      (10,10)
      (85,85)
     */
    //去重
    cid2CidRDD = cid2CidRDD.distinct()
    // 第二步：统计品类的点击次数、下单次数、付款次数
    val cid2ClickCountRDD = getClickCount(sessionId2FilterActionRDD)
    //    cid2ClickCountRDD.foreach(println(_))
    /*
    品类，点击次数
    (22,7338)
    (46,7175)
    (70,7194)
     */
    val cid2OrderCountRDD = getOrderCount(sessionId2FilterActionRDD)
    //    cid2OrderCountRDD.foreach(println(_))
    /*
   品类，下单次数
    (22,7340)
    (70,7361)
    (40,7321)
    (88,7250)
    */
    val cid2PayCountRDD = getPayCount(sessionId2FilterActionRDD)
//    cid2PayCountRDD.foreach(println(_))
    /*
      品类，付款次数
      (22,7311)
      (70,7361)
      (40,7367)
      (88,7337)
      (47,7407)
    */


    // cid2FullCountRDD: RDD[(cid, countInfo)]
    // (62,categoryid=62|clickCount=77|orderCount=65|payCount=67)
    //左外连接三个表
    val cid2FullCountRDD = getFullCount(cid2CidRDD, cid2ClickCountRDD, cid2OrderCountRDD, cid2PayCountRDD)

    // 实现自定义二次排序key
    val sortKey2FullCountRDD = cid2FullCountRDD.map{
      case (cid, countInfo) =>
        val clickCount = StringUtils.getFieldFromConcatString(countInfo, "\\|", Constants.FIELD_CLICK_COUNT).toLong
        val orderCount = StringUtils.getFieldFromConcatString(countInfo, "\\|", Constants.FIELD_ORDER_COUNT).toLong
        val payCount = StringUtils.getFieldFromConcatString(countInfo, "\\|", Constants.FIELD_PAY_COUNT).toLong

        val sortKey = SortKey(clickCount, orderCount, payCount)

        (sortKey, countInfo)
    }
//    sortKey2FullCountRDD.foreach(println(_))
    /*
    (SortKey(7158,7254,7436),categoryid=81|clickCount=7158|orderCount=7254|payCount=7436)
    (SortKey(7189,7311,7407),categoryid=47|clickCount=7189|orderCount=7311|payCount=7407)
    (SortKey(7415,7169,7400),categoryid=39|clickCount=7415|orderCount=7169|payCount=7400)
    (SortKey(7317,7330,7320),categoryid=71|clickCount=7317|orderCount=7330|payCount=7320)
     */
    val top10CategoryArray = sortKey2FullCountRDD.sortByKey(false).take(10)
//    top10CategoryArray.foreach(println(_))
    /*
    (SortKey(7470,7106,7438),categoryid=26|clickCount=7470|orderCount=7106|payCount=7438)
    (SortKey(7451,7280,7306),categoryid=28|clickCount=7451|orderCount=7280|payCount=7306)
    (SortKey(7443,7201,7367),categoryid=68|clickCount=7443|orderCount=7201|payCount=7367)
    (SortKey(7433,7210,7351),categoryid=92|clickCount=7433|orderCount=7210|payCount=7351)
    (SortKey(7429,7365,7389),categoryid=54|clickCount=7429|orderCount=7365|payCount=7389)
    (SortKey(7421,7382,7324),categoryid=84|clickCount=7421|orderCount=7382|payCount=7324)
    (SortKey(7421,7217,7090),categoryid=5|clickCount=7421|orderCount=7217|payCount=7090)
    (SortKey(7415,7169,7400),categoryid=39|clickCount=7415|orderCount=7169|payCount=7400)
    (SortKey(7411,7240,7246),categoryid=65|clickCount=7411|orderCount=7240|payCount=7246)
    (SortKey(7404,7357,7356),categoryid=76|clickCount=7404|orderCount=7357|payCount=7356)
     */


    val top10CategoryRDD = sparkSession.sparkContext.makeRDD(top10CategoryArray).map{
      case (sortKey, countInfo) =>
        val cid = StringUtils.getFieldFromConcatString(countInfo, "\\|", Constants.FIELD_CATEGORY_ID).toLong
        val clickCount = sortKey.clickCount
        val orderCount = sortKey.orderCount
        val payCount = sortKey.payCount

        Top10Category(taskUUID, cid, clickCount, orderCount, payCount)
    }

//    import sparkSession.implicits._
//    top10CategoryRDD.toDF().write
//      .format("jdbc")
//      .option("url", ConfigurationManager.config.getString(Constants.JDBC_URL))
//      .option("user", ConfigurationManager.config.getString(Constants.JDBC_USER))
//      .option("password", ConfigurationManager.config.getString(Constants.JDBC_PASSWORD))
//      .option("dbtable", "top10_category_0926")
//      .mode(SaveMode.Append)
//      .save

    top10CategoryArray
  }
```

# 需求四：Top10热门品类的Top10活跃Session统计

*yield* 关键字的简短总结:

- 针对每一次 for 循环的迭代, yield 会产生一个值，被循环记录下来 (内部实现上，像是一个缓冲区).
- 当循环结束后, 会返回所有 yield 的值组成的集合.
- 返回集合的类型与被遍历的集合类型是一致的.

```scala
 1 scala> val a = Array(1, 2, 3, 4, 5)
 2 a: Array[Int] = Array(1, 2, 3, 4, 5)
 3  
 4 scala> for (e <- a) yield e
 5 res5: Array[Int] = Array(1, 2, 3, 4, 5)
 6  
 7 scala> for (e <- a) yield e * 2
 8 res6: Array[Int] = Array(2, 4, 6, 8, 10)
 9  
10 scala> for (e <- a) yield e % 2
11 res7: Array[Int] = Array(1, 0, 1, 0, 1)
```

```scala
    val m1 = Map(
      "a"->1,
      "b"->2,
      "c"->3
    )
    val rdd = for((k,v)<-m1)yield (k,k+"="+v)
    rdd.foreach(println(_))
    /*
    (a,a=1)
    (b,b=2)
    (c,c=3)
     */
```

```scala
 // 需求四：Top10热门商品的Top10活跃session统计
    // sessionId2FilterActionRDD: RDD[(sessionId, action)]
    // top10CategoryArray: Array[(sortKey, countInfo)]
    top10ActiveSession(sparkSession, taskUUID, sessionId2FilterActionRDD, top10CategoryArray)





 def top10ActiveSession(sparkSession: SparkSession,
                         taskUUID: String,
                         sessionId2FilterActionRDD: RDD[(String, UserVisitAction)],
                         top10CategoryArray: Array[(SortKey, String)]): Unit = {
    // 第一步：过滤出所有点击过Top10品类的action
    // 1： join
    //    val cid2CountInfoRDD = sparkSession.sparkContext.makeRDD(top10CategoryArray).map{
    //      case (sortKey, countInfo) =>
    //        val cid = StringUtils.getFieldFromConcatString(countInfo, "\\|", Constants.FIELD_CATEGORY_ID).toLong
    //        (cid, countInfo)
    //    }
    //
    //      val cid2ActionRDD = sessionId2FilterActionRDD.map{
    //        case (sessionId, action) =>
    //          val cid = action.click_category_id
    //          (cid, action)
    //      }
    //
    //    val sessionId2ActionRDD = cid2CountInfoRDD.join(cid2ActionRDD).map{
    //      case (cid, (countInfo, action)) =>
    //        val sid = action.session_id
    //        (sid, action)
    //    }

    // 2：使用filter
    // cidArray: Array[Long] 包含了Top10热门品类ID
    //top10CategoryArray: Array[(sortKey, countInfo)]
    val cidArray = top10CategoryArray.map {
      case (sortKey, countInfo) =>
        val cid = StringUtils.getFieldFromConcatString(countInfo, "\\|", Constants.FIELD_CATEGORY_ID).toLong
        cid
    }

    // 所有符合过滤条件的，并且点击过Top10热门品类的action
    val sessionId2ActionRDD = sessionId2FilterActionRDD.filter {
      case (sessionId, action) =>
        cidArray.contains(action.click_category_id)
    }
    //    sessionId2ActionRDD.foreach(println(_))
    /*
    (330b8020e71a4e64bea89dee3fca0e67,UserVisitAction(2019-09-26,82,330b8020e71a4e64bea89dee3fca0e67,8,2019-09-26 8:40:22,null,54,58,null,null,null,null,0))
(69344ab863964172bbae74c0af287c36,UserVisitAction(2019-09-26,70,69344ab863964172bbae74c0af287c36,2,2019-09-26 10:14:48,null,28,67,null,null,null,null,8))
(69344ab863964172bbae74c0af287c36,UserVisitAction(2019-09-26,70,69344ab863964172bbae74c0af287c36,5,2019-09-26 10:26:39,null,39,85,null,null,null,null,2))
(69344ab863964172bbae74c0af287c36,UserVisitAction(2019-09-26,70,69344ab863964172bbae74c0af287c36,3,2019-09-26 10:17:44,null,65,8,null,null,null,null,3))
(bb906fb73784437184a1aafab1041ad2,UserVisitAction(2019-09-26,1,bb906fb73784437184a1aafab1041ad2,6,2019-09-26 12:27:56,null,39,27,null,null,null,null,6))
(1fe06487471e4b828268fea7eec18596,UserVisitAction(2019-09-26,17,1fe06487471e4b828268fea7eec18596,3,2019-09-26 2:39:29,null,68,83,null,null,null,null,7))
(1fe06487471e4b828268fea7eec18596,UserVisitAction(2019-09-26,17,1fe06487471e4b828268fea7eec18596,1,2019-09-26 2:53:30,null,28,44,null,null,null,null,8))
(1fe06487471e4b828268fea7eec18596,UserVisitAction(2019-09-26,17,1fe06487471e4b828268fea7eec18596,7,2019-09-26 2:50:09,null,54,44,null,null,null,null,7))
(413f4375e02e4c8485646ef46c4d3c28,UserVisitAction(2019-09-26,78,413f4375e02e4c8485646ef46c4d3c28,8,2019-09-26 14:51:15,null,28,53,null,null,null,null,7))
     */

    // 按照sessionId进行聚合操作
    val sessionId2GroupRDD = sessionId2ActionRDD.groupByKey()
    //    sessionId2GroupRDD.foreach(println(_))
    //(9bd21f70c8f94e0399a5287c2286595d,CompactBuffer(UserVisitAction(2019-09-26,8,9bd21f70c8f94e0399a5287c2286595d,7,2019-09-26 1:43:07,null,68,7,null,null,null,null,6), UserVisitAction(2019-09-26,8,9bd21f70c8f94e0399a5287c2286595d,9,2019-09-26 1:39:45,null,84,38,null,null,null,null,2)))


    // cid2SessionCountRDD: RDD[(cid, sessionCount)]
    val cid2SessionCountRDD = sessionId2GroupRDD.flatMap {
      case (sessionId, iterableAction) =>

        val categoryCountMap = new mutable.HashMap[Long, Long]()

        for (action <- iterableAction) {
          val cid = action.click_category_id
          if (!categoryCountMap.contains(cid))
            categoryCountMap += (cid -> 0)
          categoryCountMap.update(cid, categoryCountMap(cid) + 1)
        }

        // 记录了一个session对于它所有点击过的品类的点击次数
        for ((cid, count) <- categoryCountMap)
          yield (cid, sessionId + "=" + count)
    }
    //    cid2SessionCountRDD.foreach(println(_))
    /*
    (5,7302464abd374cafb375b2524c2ed5f1=1)
(65,a300a96503d342d4b4a953304c4b8e4f=1)
(5,a300a96503d342d4b4a953304c4b8e4f=1)
(54,a300a96503d342d4b4a953304c4b8e4f=1)
(92,4ad045e25c66451e8de904ced237673e=1)
(68,4ad045e25c66451e8de904ced237673e=1)
(54,4ad045e25c66451e8de904ced237673e=1)
(39,60c7db8903e7442e82aaadd8e6657e97=1)
     */

    // cid2GroupRDD每一条数据都是一个categoryid和它对应的所有点击过它的session对它的点击次数
    val cid2GroupRDD = cid2SessionCountRDD.groupByKey()
    //    cid2GroupRDD.foreach(println(_))
    /*

5,
CompactBuffer(
59fd2a25ae1b417fa4344ddaaf519758=1,
3f262752447b4c6f98594786a7b4e1ef=1,
b6ea96d777704da79d1d6cab6a4ac606=1,
 a068de1fef344f2da595a3131fd33ce4=1,
...
     */


    // top10SessionRDD: RDD[Top10Session]
    val top10SessionRDD = cid2GroupRDD.flatMap {
      case (cid, iterableSessionCount) =>
        // true: item1放在前面
        // flase: item2放在前面
        // item: sessionCount   String   "sessionId=count"
        val sortList = iterableSessionCount.toList.sortWith((item1, item2) => {
          item1.split("=")(1).toLong > item2.split("=")(1).toLong
        }).take(10)

        val top10Session = sortList.map {
          // item : sessionCount   String   "sessionId=count"
          case item =>
            val sessionId = item.split("=")(0)
            val count = item.split("=")(1).toLong
            Top10Session(taskUUID, cid, sessionId, count)
        }

        top10Session
    }

//    import sparkSession.implicits._
//    top10SessionRDD.toDF().write
//      .format("jdbc")
//      .option("url", ConfigurationManager.config.getString(Constants.JDBC_URL))
//      .option("user", ConfigurationManager.config.getString(Constants.JDBC_USER))
//      .option("password", ConfigurationManager.config.getString(Constants.JDBC_PASSWORD))
//      .option("dbtable", "top10_session_0926")
//      .mode(SaveMode.Append)
//      .save()


  }
```

# 需求五：页面单跳转化率统计



```scala
import java.util.UUID

import commons.conf.ConfigurationManager
import commons.constant.Constants
import commons.model.UserVisitAction
import commons.utils.{DateUtils, ParamUtils}
import net.sf.json.JSONObject
import org.apache.spark.SparkConf
import org.apache.spark.sql.{SaveMode, SparkSession}

import scala.collection.mutable

object PageConvertStat {

  def main(args: Array[String]): Unit = {

    // 获取任务限制条件
    val jsonStr = ConfigurationManager.config.getString(Constants.TASK_PARAMS)
    val taskParam = JSONObject.fromObject(jsonStr)

    // 获取唯一主键
    val taskUUID = UUID.randomUUID().toString

    // 创建sparkConf
    val sparkConf = new SparkConf().setAppName("pageConvert").setMaster("local[*]")

    // 创建sparkSession
    val sparkSession = SparkSession.builder().config(sparkConf).enableHiveSupport().getOrCreate()

    // 获取用户行为数据
    val sessionId2ActionRDD = getUserVisitAction(sparkSession, taskParam)
    //    sessionId2ActionRDD.foreach(println(_))
    //(59ac1e7777994d20a59bb66f792eaa2c,UserVisitAction(2019-09-26,66,59ac1e7777994d20a59bb66f792eaa2c,9,2019-09-26 17:43:24,null,-1,-1,null,null,64,56,2))
    //(1772badf72a7479ab35ac55c03c79663,UserVisitAction(2019-09-26,9,1772badf72a7479ab35ac55c03c79663,0,2019-09-26 12:06:55,null,-1,-1,null,null,88,77,5))
    //(59ac1e7777994d20a59bb66f792eaa2c,UserVisitAction(2019-09-26,66,59ac1e7777994d20a59bb66f792eaa2c,6,2019-09-26 17:26:52,null,69,21,null,null,null,null,5))
    // pageFlowStr: "1,2,3,4,5,6,7"
    //查找的条件  页面访问路径为1,2,3,4,5,6,7
    val pageFlowStr = ParamUtils.getParam(taskParam, Constants.PARAM_TARGET_PAGE_FLOW)
    // pageFlowArray: Array[Long]  [1,2,3,4,5,6,7]
    val pageFlowArray = pageFlowStr.split(",")
    // pageFlowArray.slice(0, pageFlowArray.length - 1): [1,2,3,4,5,6]
    // pageFlowArray.tail: [2,3,4,5,6,7]
    // pageFlowArray.slice(0, pageFlowArray.length - 1).zip(pageFlowArray.tail): [(1,2), (2,3) , ..]
    // targetPageSplit: [1_2, 2_3, 3_4, ...]
    val targetPageSplit = pageFlowArray.slice(0, pageFlowArray.length - 1).zip(pageFlowArray.tail).map {
      case (page1, page2) => page1 + "_" + page2
    }

    // sessionId2ActionRDD: RDD[(sessionId, action)]
    val sessionId2GroupRDD = sessionId2ActionRDD.groupByKey()

    // pageSpllitNumRDD: RDD[(String, 1L)]
    val pageSpllitNumRDD = sessionId2GroupRDD.flatMap {
      case (sessionId, iterableAction) =>
        // item1: action
        // item2: action
        // sortList: List[UserVisitAction]
        val sortList = iterableAction.toList.sortWith((item1, item2) => {
          DateUtils.parseTime(item1.action_time).getTime < DateUtils.parseTime(item2.action_time).getTime
        })

        // pageList: List[Long]  [1,2,3,4,...]
        val pageList = sortList.map {
          case action => action.page_id
        }

        // pageList.slice(0, pageList.length - 1): [1,2,3,..,N-1]
        // pageList.tail: [2,3,4,..,N]
        // pageList.slice(0, pageList.length - 1).zip(pageList.tail): [(1,2), (2,3), ...]
        // pageSplit: [1_2, 2_3, ...]
        val pageSplit = pageList.slice(0, pageList.length - 1).zip(pageList.tail).map {
          case (page1, page2) => page1 + "_" + page2
        }

        val pageSplitFilter = pageSplit.filter {
          case pageSplit => targetPageSplit.contains(pageSplit)
        }

        pageSplitFilter.map {
          case pageSplit => (pageSplit, 1L)
        }


    }

    // pageSplitCountMap: Map[(pageSplit, count)]
    val pageSplitCountMap = pageSpllitNumRDD.countByKey()

    val startPage = pageFlowArray(0).toLong

    val startPageCount = sessionId2ActionRDD.filter {
      case (sessionId, action) => action.page_id == startPage
    }.count()
    getPageConvert(sparkSession, taskUUID, targetPageSplit, startPageCount, pageSplitCountMap)

  }
  def getPageConvert(sparkSession: SparkSession,
                     taskUUID: String,
                     targetPageSplit: Array[String],
                     startPageCount: Long,
                     pageSplitCountMap: collection.Map[String, Long]): Unit = {

    val pageSplitRatio = new mutable.HashMap[String, Double]()

    var lastPageCount = startPageCount.toDouble

    // 1,2,3,4,5,6,7
    // 1_2,2_3,...
    for(pageSplit <- targetPageSplit){
      // 第一次循环： lastPageCount: page1   currentPageSplitCount: page1_page2      结果：page1_page2
      val currentPageSplitCount = pageSplitCountMap.get(pageSplit).get.toDouble
      val ratio = currentPageSplitCount / lastPageCount
      pageSplitRatio.put(pageSplit, ratio)
      lastPageCount = currentPageSplitCount
    }

    val convertStr = pageSplitRatio.map{
      case (pageSplit, ratio) => pageSplit + "=" + ratio
    }.mkString("|")

    val pageSplit = PageSplitConvertRate(taskUUID, convertStr)

    val pageSplitRatioRDD = sparkSession.sparkContext.makeRDD(Array(pageSplit))
    //5_6=0.9980356159353773|2_3=0.993542535824415|6_7=1.0003678972830785|3_4=0.9963303757257093|4_5=0.9981126197936708|1_2=0.09912133868644898
    import sparkSession.implicits._
    pageSplitRatioRDD.toDF().write
      .format("jdbc")
      .option("url", ConfigurationManager.config.getString(Constants.JDBC_URL))
      .option("dbtable", "page_split_convert_rate_0926")
      .option("user", ConfigurationManager.config.getString(Constants.JDBC_USER))
      .option("password", ConfigurationManager.config.getString(Constants.JDBC_PASSWORD))
      .mode(SaveMode.Append)
      .save()

  }
  def getUserVisitAction(sparkSession: SparkSession, taskParam: JSONObject) = {
    val startDate = ParamUtils.getParam(taskParam, Constants.PARAM_START_DATE)
    val endDate = ParamUtils.getParam(taskParam, Constants.PARAM_END_DATE)

    val sql = "select * from user_visit_action where date>='" + startDate + "' and date<='" +
      endDate + "'"

    import sparkSession.implicits._
    sparkSession.sql(sql).as[UserVisitAction].rdd.map(item => (item.session_id, item))
  }

}

```

# 需求六：各区域 Top3 商品统计

| 区域等级 | 地区名称   |
| -------- | ---------- |
| A 级     | 华北、华东 |
| B 级     | 华南、华中 |
| C 级     | 西北、西南 |
| D 级     | 东北、其他 |

```scala
case class CityClickProduct(city_id:Long,
                                click_product_id:Long)

case class CityAreaInfo(city_id:Long,
                          city_name:String,
                          area:String)

//***************** 输出表 *********************

/**
  *
  * @param taskid主键ID
  * @param area区域
  * @param areaLevel区域等级
  * @param productid商品ID
  * @param cityInfos 城市信息 (cityId1:cityName1,…, cityIdN:cityNameN)
  * @param clickCount点击次数
  * @param productName商品名称
  * @param productStatus商品类型
  */
case class AreaTop3Product(taskid:String,
                           area:String,
                           areaLevel:String,
                           productid:Long,
                           cityInfos:String,
                           clickCount:Long,
                           productName:String,
                           productStatus:String)
```

```sh
Array((0L, "北京", "华北"), (1L, "上海", "华东"), (2L, "南京", "华东"), (3L, "广州", "华南"),
(4L, "三亚", "华南"), (5L, "武汉", "华中"), (6L, "长沙", "华中"), (7L, "西安", "西北"), (8L,
"成都", "西南"), (9L, "哈尔滨", "东北"))
```

```scala

```

